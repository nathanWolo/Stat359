

## Question 1

As always, the first step is to load the data into R.

```{r load_data}
data <- read.csv("LungCancer.csv")
summary(data)

```

Then we make the contingency table

```{r q1conttable}

contingency_table <- table(data$Smoker, data$Case)
rownames(contingency_table) <- c("Smoker", "Non Smoker")
colnames(contingency_table) <- c("Case", "No Case")
print(contingency_table)


```

Then we compute the table of expected outputs

```{r q1exp_outputs}

row_totals <- rowSums(contingency_table)
col_totals <- colSums(contingency_table)
grand_total <- sum(contingency_table)

expected_counts <- outer(row_totals, col_totals) / grand_total
print(expected_counts)

```

Calculating the test statistic by hand:

```{r q1test_stat}
observed_chi_squared <- sum((contingency_table - expected_counts)^2 / expected_counts)
print(paste("Observed chi-squared value:", observed_chi_squared))

```

The distribution of the test statistic follows a chi-squared distribution with (rows - 1) * (columns - 1) degrees of freedom, assuming no association between smoking and lung cancer (i.e that the null hypothesis is true). In this case, with a 2x2 table, it follows a chi-squared distribution with 1 degree of freedom.


We can use the chi squared test to compute a p value for our observations under the null hypothesis.

```{r q1p_value}

chi_squared_test <- chisq.test(contingency_table)
p_value <- chi_squared_test$p.value
print(paste("Chi-squared value:", chi_squared_test$statistic))
print(paste("P-value:", p_value))

```
In conclusion, our analysis of the data reveals a significant association between smoking and lung cancer. The p-value obtained from the chi-squared test is extremely low (2.64e-05), which indicates that, if there were no association between smoking and lung cancer, it would be incredibly unlikely to observe a test statistic as extreme as the one observed in our data.

Comparing the observed and expected counts in the contingency tables, we can see that smokers have a significantly higher rate of lung cancer, while non-smokers have a lower rate than expected under the null hypothesis. This further supports the presence of a significant association between smoking and lung cancer.


## Question 2

We start by loading the data and creating a contingency table:

```{r q2_load_data}
library(knitr)

observed_counts <- matrix(c(7, 7, 7, 13,
                            27, 34, 12, 18,
                            55, 52, 11, 24),
                          nrow = 3,
                          byrow = TRUE)

rownames(observed_counts) <- c("Moderate-advanced", "Minimal", "Not Present")
colnames(observed_counts) <- c("O", "A", "AB", "B")
contingency_table <- as.table(observed_counts)
kable(contingency_table, caption = "Contingency Table")


```

Next, we can compute a table of expected outputs:

```{r q2_expected_table}
row_totals <- rowSums(contingency_table)
col_totals <- colSums(contingency_table)
grand_total <- sum(contingency_table)

expected_counts <- outer(row_totals, col_totals) / grand_total
kable(expected_counts, caption = "Expected Counts Table")

```

Then, we can compute the value of the test statistic manually:

```{r q2_manual_test_stat}

observed_chi_squared <- sum((contingency_table - expected_counts)^2 / expected_counts)
paste("Observed chi-squared value:", observed_chi_squared)

```

The distribution of the test statistic follows a chi-squared distribution with (rows - 1) * (columns - 1) degrees of freedom, assuming no association between disease and blood group. In this case, with a 3x4 table, it follows a chi-squared distribution with (3 - 1) * (4 - 1) = 6 degrees of freedom.

Finally, we compute the p-value using the chi-squared test and provide a conclusion.

```{r q2_conclusion}
chi_squared_test <- chisq.test(contingency_table)
p_value <- chi_squared_test$p.value
paste("Chi-squared value:", chi_squared_test$statistic)
paste("P-value:", p_value)
```

In conclusion, our analysis of the data reveals a significant association between tuberculosis disease severity and blood group within the ABO system. The p-value obtained from the chi-squared test is relatively low (0.013), which indicates that, if there were no association between the disease and blood group, it would be quite unlikely to observe a test statistic as extreme as the one observed in our data (16.14). So it would be reasonable to reject the null hypothesis, that is: the assumption that there is no relation between the severity of tuberculosis and the blood type.

Comparing the observed and expected counts in the tables, we can see that the counts do differ considerably from what we would expect under the null hypothesis. For example, the number of cases with moderate-advanced severity is notably lower for blood group O and higher for blood group B than expected. This supports the presence of a significant association between tuberculosis disease severity and blood group within the ABO system.

## Question 3

Let's load the data and generate the scatterplot:

```{r q3_load_data}
library(ggplot2)
library(gridExtra)
library(readr)
# Read the CSV file line by line
lines <- readLines("anscombe.csv")

# Find the starting and ending line numbers for each dataset
start_lines <- grep("^DATASET", lines)
end_lines <- c(start_lines[-1] - 1, length(lines))

# Read each dataset into a data frame
dataset1 <- read.csv(text = paste(lines[(start_lines[1] + 1):(end_lines[1] - 1)], collapse = "\n"), header = TRUE)
dataset2 <- read.csv(text = paste(lines[(start_lines[2] + 1):(end_lines[2] - 1)], collapse = "\n"), header = TRUE)
dataset3 <- read.csv(text = paste(lines[(start_lines[3] + 1):(end_lines[3] - 1)], collapse = "\n"), header = TRUE)
dataset4 <- read.csv(text = paste(lines[(start_lines[4] + 1):end_lines[4]], collapse = "\n"), header = TRUE)

plot1 <- ggplot(dataset1, aes(x = Set1x, y = Set1y)) + geom_point() +
  labs(title = "Dataset 1", x = "X", y = "Y") + theme_minimal()

plot2 <- ggplot(dataset2, aes(x = Set2x, y = Set2y)) + geom_point() +
  labs(title = "Dataset 2", x = "X", y = "Y") + theme_minimal()

plot3 <- ggplot(dataset3, aes(x = Set3x, y = Set3y)) + geom_point() +
  labs(title = "Dataset 3", x = "X", y = "Y") + theme_minimal()

plot4 <- ggplot(dataset4, aes(x = Set4x, y = Set4y)) + geom_point() +
  labs(title = "Dataset 4", x = "X", y = "Y") + theme_minimal()

grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)


```


Dataset 1 exhibits some variability at smaller scales, yet a discernible linear trend is present across the entire range.

Dataset 2 displays an initial linear increase followed by a more parabolic pattern in the second half, characterized by a distinct non-linear bend and decrease.

Dataset 3 largely follows a linear pattern, with a notable outlier around $x \approx 13$.

Dataset 4 features data points clustered around the same x value, suggesting that the chosen explanatory variable may be inadequate or that the data is not suitable for linear regression analysis.

```{r q3_lr}
# Perform simple linear regression for each dataset
lm1 <- lm(Set1y ~ Set1x, data = dataset1)
lm2 <- lm(Set2y ~ Set2x, data = dataset2)
lm3 <- lm(Set3y ~ Set3x, data = dataset3)
lm4 <- lm(Set4y ~ Set4x, data = dataset4)

# Add regression lines to the scatter plots
plot1 <- plot1 + geom_smooth(method = "lm", se = FALSE, color = "red")
plot2 <- plot2 + geom_smooth(method = "lm", se = FALSE, color = "red")
plot3 <- plot3 + geom_smooth(method = "lm", se = FALSE, color = "red")
plot4 <- plot4 + geom_smooth(method = "lm", se = FALSE, color = "red")

# Display the scatter plots with regression lines
grid.arrange(plot1, plot2, plot3, plot4, ncol = 2)

# Calculate R-squared values
r_squared_1 <- summary(lm1)$r.squared
r_squared_2 <- summary(lm2)$r.squared
r_squared_3 <- summary(lm3)$r.squared
r_squared_4 <- summary(lm4)$r.squared

# Create a table showing the R-squared values for each dataset
r_squared_table <- data.frame(
  Dataset = c("Dataset 1", "Dataset 2", "Dataset 3", "Dataset 4"),
  R_Squared = c(r_squared_1, r_squared_2, r_squared_3, r_squared_4)
)

# Print the table
library(knitr)
kable(r_squared_table, caption = "R-squared values for each dataset")

```

The results show that despite the different shapes of the datasets, they all have approximately the same R-squared value. This is due to the clever arrangement of data points that results in the same R-squared value when fitting a linear regression. Dataset 1 and 3 show a decent linear fit, while dataset 2 somewhat fits the data but fails to capture the parabolic trend. Dataset 4 is not suitable for linear regression modeling, as the fitted trend is nonsensical. The R-squared value, being the square of the sample correlation coefficient, is not always the best indicator of a model's fit, as demonstrated by these datasets.

## Question 4



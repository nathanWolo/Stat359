---
title: "Assignment2"
output: html_document
date: "2023-02-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

We need to generate samples from the requested distributions. We can do so with the following code:


```{r samples}



# Specify the sample sizes and number of samples
sample_sizes <- c(10, 20, 50, 100, 1000)
num_samples <- c(10, 100, 1000, 10000)

# Create list objects to store the samples
samples_uniform <- list()
samples_poisson <- list()
samples_binomial <- list()

# Generate the samples using a for loop
for (i in seq_along(sample_sizes)) {
  m <- sample_sizes[i]
  samples_uniform[[i]] <- list()
  samples_poisson[[i]] <- list()
  samples_binomial[[i]] <- list()
  for (j in seq_along(num_samples)) {
    n <- num_samples[j]
    samples_uniform[[i]][[j]] <- replicate(m, runif(n, 0, 1))
    samples_poisson[[i]][[j]] <- replicate(m, rpois(n, 5))
    samples_binomial[[i]][[j]] <- replicate(m, rbinom(n, 1, 0.2))
  }
}

# Calculate the sample means
mean_samples_uniform <- lapply(samples_uniform, function(x) {
  lapply(x, rowMeans)
})

mean_samples_poisson <- lapply(samples_poisson, function(x) {
  lapply(x, rowMeans)
})

mean_samples_binomial <- lapply(samples_binomial, function(x) {
  lapply(x, rowMeans)
})

# Plot the histograms of the sample means
par(mfrow=c(4,3), cex=0.4, mar = rep(2, 4))
for (i in seq_along(sample_sizes)) {
  for (j in seq_along(num_samples)) {
    hist(mean_samples_uniform[[i]][[j]], main=paste("Uniform: sample_size=", sample_sizes[i], "num_samples=", num_samples[j]),
         xlab="Sample Mean", col="red", breaks=30)
    hist(mean_samples_poisson[[i]][[j]], main=paste("Poisson: sample_size=", sample_sizes[i], "num_samples=", num_samples[j]),
         xlab="Sample Mean", col="blue", breaks=30)
    hist(mean_samples_binomial[[i]][[j]], main=paste("Binomial: sample_size=", sample_sizes[i], "num_samples=", num_samples[j]),
         xlab="Sample Mean", col="green", breaks=30)
  }
}


      
      
```

The CLT states that, for iid samples, the standardized sample mean tends towards the standard normal distribution even if the random variables being sampled are not normally distributed. First we can see the effect of fixing the sample size and increasing the number of samples. This leads to the familiar "bell" shape of the standard normal (I added an even higher value for num_samples at the end to make this even more explicit). If we fix the number of samples and increase the sample size, we can observe that the variance decreases (i.e the x axis becomes a smaller band of values).

The outcome is the same for all three distributions, this is because the CLT and law of large numbers applies to any sequence of iid random variables*.

*if the variance of the RVs are finite, which it is for all of these.

## Question 2


First, read in the data

```{r readq2}

# Read the txt file into a data frame
salt <- read.table("salt.txt", header = TRUE, sep = "\t")

# View the data frame
head(salt)
```

Now let's visualize the data

```{r plot_salt}

# Load the ggplot2 library
library(ggplot2)

# Create a histogram of the salt variable
ggplot(salt, aes(x = salt)) +
  geom_histogram(fill = "blue", color = "black") +
  labs(x = "Saltiness", y = "Frequency", title = "Histogram of Salt")


stereogram<-read.table(file ='salt.txt', sep="",header=TRUE)
salty<-stereogram$salt
boxplot(salt,col='green',names=c('salty'))
title('salty')

qqnorm(salty,main='salty')

```

Next we can find the skew and kurtosis:

```{r moments}

# Load the moments package
library(moments)

# Estimate the skewness of the salt variable
skewness(salt$salt)

# Estimate the kurtosis of the salt variable
kurtosis(salt$salt)

```

And now, using a bootstrap to estimate a 95% confidence interval for the skew:

```{r skewstrap}
# Load the moments and boot packages
library(moments)
library(boot)

# Define a function to compute skewness
boot_skew <- function(x, i) {
  return(skewness(x[i]))
}

# Define a function to compute kurtosis
boot_kurt <- function(x, i) {
  return(kurtosis(x[i]))
}

# Set the number of bootstrap replicates
B <- 1000

# Generate bootstrap samples and compute skewness
skewboot_results <- boot(salt$salt, boot_skew, R = B)
kurtboot_results <- boot(salt$salt, boot_kurt, R = B)
# View the bootstrap results
skewboot_results
kurtboot_results
# Calculate the bootstrap confidence interval
skewboot_ci <- quantile(skewboot_results$t, c(0.025, 0.975))

# Print the bootstrap estimate and confidence interval
cat("Bootstrap skewness estimate: ", mean(skewboot_results$t), "\n")
cat("Bootstrap 95% confidence interval: [", skewboot_ci[1], ", ", skewboot_ci[2], "]\n")

# Calculate the bootstrap confidence interval
kurtboot_ci <- quantile(kurtboot_results$t, c(0.025, 0.975))

# Print the bootstrap estimate and confidence interval
cat("Bootstrap kurtosis estimate: ", mean(kurtboot_results$t), "\n")
cat("Bootstrap 95% confidence interval: [", kurtboot_ci[1], ", ", kurtboot_ci[2], "]\n")
```

Judging from the visualizations and values, it seems like the distribution might have positive skew and positive kurtosis, but it is hard to make a definitive statement given the small sample size. The confidence interval for the kurtosis is strongly positive, while for the skew it is only slightly more positive than negative. So we can be more confident about positive kurtosis than positive skew.

## Question 3

```{r load_fecundity}
# Read the txt file into a data frame
fec <- read.table("fecundity.txt", header = TRUE)

# View the data frame
head(fec)

# Create a histogram of the salt variable
ggplot(fec, aes(x = fec$RS)) +
  geom_histogram(fill = "green", color = "black") +
  labs(x = "fecundity", y = "Frequency", title = "Histogram of fecundity for RS")

# Create a histogram of the salt variable
ggplot(fec, aes(x = fec$NS)) +
  geom_histogram(fill = "blue", color = "black") +
  labs(x = "fecundity", y = "Frequency", title = "Histogram of fecundity for NS")


boxplot(fec$RS,col='green',names=c('fecundity'))
title('fecundity for RS')

boxplot(fec$NS,col='blue',names=c('fecundity'))
title('fecundity for NS')


qqnorm(fec$RS,main='fecundity for RS')
qqnorm(fec$NS,main='fecundity for NS')

rs_mean <- mean(fec$RS)
ns_mean <- mean(fec$NS)
rs_mean
ns_mean

rs_var <- var(fec$RS)
ns_var <- var(fec$NS)
rs_var
ns_var

```

We can clearly see that yes, the two populations do differ both in the mean of their fecundity and the variance.

## Question 4


```{r fabric_a}
# read in the text file
# 1. Read the text file
lines <- readLines("fabric.txt")

# 2. Split each row into separate elements
data_list <- strsplit(lines, " ")

# 3. Convert character elements to numeric
data_list <- lapply(data_list, as.numeric)
# 
data_list

hvals <- as.vector(t(data_list[[1]][-1]))

pvals <- as.vector(t(data_list[[3]][-1]))

hvals 
pvals
fab_data <- data.frame(col1=hvals, col2=pvals)
colnames(fab_data) <- c("H", "P")
head(fab_data)

qqnorm(fab_data$H,main='H')
qqnorm(fab_data$P,main='P')

# Create the box plot
my_plot <- ggplot(fab_data, aes(x = factor(1), y = H, fill = "H")) +
  geom_boxplot() +
  geom_boxplot(aes(x = factor(2), y = P, fill = "P")) +
  scale_fill_manual(values = c("H" = "red", "P" = "blue")) +
  xlab("") +
  ylab("Values") +
  ggtitle("Comparative Box Plot for H and P")

# Print the plot
print(my_plot)

mean(fab_data$H)
mean(fab_data$P)

```

The high quality qqnorm is basically linear, indicating that it is drawn from a normal distribution. The poor quality qqnorm shows positive skew, and is asymmetric. The box plot shows that H has a slightly higher mean, but given that the sample size is small (especially for p) it is hard to confidently say that the true average for H is higher.
